{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Relic Welcome to the relic docs, relic is a functional relational programming library for Clojure and Clojurescript. If you don't know how you got here, best start with the README .","title":"Intro"},{"location":"#relic","text":"Welcome to the relic docs, relic is a functional relational programming library for Clojure and Clojurescript. If you don't know how you got here, best start with the README .","title":"Relic"},{"location":"agg/","text":":agg Relic provides a means to group rows and run aggregations on them. This analogous to SQL GROUP BY . Say you have a table of maps representing customer orders, and you want to compute some stats per customer: [[ :from :Order ] [ :agg ;; the first arg to :agg is the grouping vector ;; the columns to group by (can be empty for all rows) [ :customer-id ] ;; the rest of the args are aggregate extensions to the grouped ;; columns [ :total-spend [ rel/sum :total ]] [ :average-spend [ rel/avg :total ]] [ :order-count count ]]] ;; given an initial state { :Order [{ :customer-id 42 , :total 12.0 M } { :customer-id 42 , :total 25.0 M }]} ;; the results would be ({ :customer-id 42 , :average-spend 18.5 M , :order-count 2 , :total-spend 37.0 M }) Let's break down the shape of the :agg operator: [:agg cols & agg-bindings] The cols will be a vector of column names, so in the example above [:customer-id] is used so we will be aggregating over rows grouped by their customer-id. You could have used [:customer-id, :delivery-date] or any combination of columns. The empty vector [] can be used to group over all rows. Each agg-binding is a vector tuple [binding agg-expr] , the binding is the name of the new column you want the aggregated value to sit under, the agg-expr consists of an aggregation function (and any arguments). So for [:total-spend [rel/sum :total]] :total-spend is the binding rel/sum is an aggregation function Aggregation functions are built-in, they are not normal functions unfortunately - this is necessary for materialized views to work. You may later be able to extend relic with user defined aggregations, but the tools for that are not final. See also: aggregates for aggregate functions that you can use. N.B Empty relations If you are aggregating over all rows, :agg will always return a row, even if the input relation is empty. e.g you will get {:count 0} back (not nil ) if you ask for a count of all rows and there are no rows.","title":":agg"},{"location":"agg/#agg","text":"Relic provides a means to group rows and run aggregations on them. This analogous to SQL GROUP BY . Say you have a table of maps representing customer orders, and you want to compute some stats per customer: [[ :from :Order ] [ :agg ;; the first arg to :agg is the grouping vector ;; the columns to group by (can be empty for all rows) [ :customer-id ] ;; the rest of the args are aggregate extensions to the grouped ;; columns [ :total-spend [ rel/sum :total ]] [ :average-spend [ rel/avg :total ]] [ :order-count count ]]] ;; given an initial state { :Order [{ :customer-id 42 , :total 12.0 M } { :customer-id 42 , :total 25.0 M }]} ;; the results would be ({ :customer-id 42 , :average-spend 18.5 M , :order-count 2 , :total-spend 37.0 M }) Let's break down the shape of the :agg operator: [:agg cols & agg-bindings] The cols will be a vector of column names, so in the example above [:customer-id] is used so we will be aggregating over rows grouped by their customer-id. You could have used [:customer-id, :delivery-date] or any combination of columns. The empty vector [] can be used to group over all rows. Each agg-binding is a vector tuple [binding agg-expr] , the binding is the name of the new column you want the aggregated value to sit under, the agg-expr consists of an aggregation function (and any arguments). So for [:total-spend [rel/sum :total]] :total-spend is the binding rel/sum is an aggregation function Aggregation functions are built-in, they are not normal functions unfortunately - this is necessary for materialized views to work. You may later be able to extend relic with user defined aggregations, but the tools for that are not final. See also: aggregates for aggregate functions that you can use.","title":":agg"},{"location":"agg/#nb-empty-relations","text":"If you are aggregating over all rows, :agg will always return a row, even if the input relation is empty. e.g you will get {:count 0} back (not nil ) if you ask for a count of all rows and there are no rows.","title":"N.B Empty relations"},{"location":"aggregates/","text":"Aggregates The :agg operator permits the use of aggregate functions, such as count, sum and so on. See below for a listing of what you can do. Stats max the max val by some expr . min the min val by some expr . rel/max-by the max row by some expr . rel/min-by the min row by some expr . Top or bottom N rel/bottom find the lowest n vals for some expr . rel/bottom-by find the lowest n rows for some expr . rel/top find the biggest n vals for some expr . rel/top-by find the biggest n rows for some expr . Counts count row count, or row count for all rows meeting some predicate . rel/count-distinct val count for all distinct vals of some expr . Other rel/any / rel/not-any check if any row meets a predicate (or not). rel/sum sum over some expr . rel/set-concat build sets by some expr over grouped rows.","title":"Aggregates"},{"location":"aggregates/#aggregates","text":"The :agg operator permits the use of aggregate functions, such as count, sum and so on. See below for a listing of what you can do. Stats max the max val by some expr . min the min val by some expr . rel/max-by the max row by some expr . rel/min-by the min row by some expr . Top or bottom N rel/bottom find the lowest n vals for some expr . rel/bottom-by find the lowest n rows for some expr . rel/top find the biggest n vals for some expr . rel/top-by find the biggest n rows for some expr . Counts count row count, or row count for all rows meeting some predicate . rel/count-distinct val count for all distinct vals of some expr . Other rel/any / rel/not-any check if any row meets a predicate (or not). rel/sum sum over some expr . rel/set-concat build sets by some expr over grouped rows.","title":"Aggregates"},{"location":"any/","text":"any An aggregate function that tests if for any row in the group (pred row) returns truthy, accepts a expr as an arg. e.g ;; in this example, we use any to test if the customer has ;; any order total over 35 [[ :from :Order ] [ :agg [ :customer-id ] [ :has-high-valued-order [ rel/any [ <= 35.0 M :total ]]]]] ;; TABLE STATE { :Order [{ :customer-id 42 , :total 10.0 M } { :customer-id 42 , :total 12.0 M } { :customer-id 43 , :total 50.0 M }]} ;; RESULT [{ :customer-id 42 , :has-high-valued-order false } { :customer-id 43 , :has-high-valued-order true }]","title":"any"},{"location":"any/#any","text":"An aggregate function that tests if for any row in the group (pred row) returns truthy, accepts a expr as an arg. e.g ;; in this example, we use any to test if the customer has ;; any order total over 35 [[ :from :Order ] [ :agg [ :customer-id ] [ :has-high-valued-order [ rel/any [ <= 35.0 M :total ]]]]] ;; TABLE STATE { :Order [{ :customer-id 42 , :total 10.0 M } { :customer-id 42 , :total 12.0 M } { :customer-id 43 , :total 50.0 M }]} ;; RESULT [{ :customer-id 42 , :has-high-valued-order false } { :customer-id 43 , :has-high-valued-order true }]","title":"any"},{"location":"avg/","text":"avg An aggregate function that computes the average for all sampled values by some expr . In the below example, we use avg to compute the average-order-value (aov) over a group of orders. ;; QUERY [[ :from :Order ] [ :agg [] [ :aov [ rel/avg :total ]]]] ;; STATE { :Order [{ :total 10.0 M } { :total 25.0 M }]} ;; RESULT [{ :aov 17.5 M }]","title":"avg"},{"location":"avg/#avg","text":"An aggregate function that computes the average for all sampled values by some expr . In the below example, we use avg to compute the average-order-value (aov) over a group of orders. ;; QUERY [[ :from :Order ] [ :agg [] [ :aov [ rel/avg :total ]]]] ;; STATE { :Order [{ :total 10.0 M } { :total 25.0 M }]} ;; RESULT [{ :aov 17.5 M }]","title":"avg"},{"location":"bottom-by/","text":"bottom-by An aggregate function that returns the lowest n rows by some expr . In the below example, we bind the bottom 5 lowest scoring players. ;; QUERY [[ :from :Player ] [ :agg [] [ :lowest-scoring [ rel/bottom-by 5 :score ]]]] ;; STATE { :Player [{ :score 1 :name \"alice\" } { :score 200 :name \"bob\" } { :score 4323 :name \"fred\" } { :score 5555 :name \"hannah\" } { :score 4242 :name \"george\" } { :score -123 :name \"isabel\" } { :score 330 :name \"dave\" }]} ;; RESULT [{ :lowest-scoring [{ :score -123 , :name \"isabel\" } { :score 1 , :name \"alice\" } { :score 200 , :name \"bob\" } { :score 330 , :name \"dave\" } { :score 4242 , :name \"george\" }]}]","title":"bottom-by"},{"location":"bottom-by/#bottom-by","text":"An aggregate function that returns the lowest n rows by some expr . In the below example, we bind the bottom 5 lowest scoring players. ;; QUERY [[ :from :Player ] [ :agg [] [ :lowest-scoring [ rel/bottom-by 5 :score ]]]] ;; STATE { :Player [{ :score 1 :name \"alice\" } { :score 200 :name \"bob\" } { :score 4323 :name \"fred\" } { :score 5555 :name \"hannah\" } { :score 4242 :name \"george\" } { :score -123 :name \"isabel\" } { :score 330 :name \"dave\" }]} ;; RESULT [{ :lowest-scoring [{ :score -123 , :name \"isabel\" } { :score 1 , :name \"alice\" } { :score 200 , :name \"bob\" } { :score 330 , :name \"dave\" } { :score 4242 , :name \"george\" }]}]","title":"bottom-by"},{"location":"bottom/","text":"bottom An aggregate functions that returns the lowest n values for some expr across the group. In the below example we use bottom to find the lowest 5 scores for a table of Player data. ;; QUERY [[ :from :Player ] [ :agg [] [ :lowest-scores [ rel/bottom 5 :score ]]]] ;; STATE { :Player [{ :score 1 } { :score 200 } { :score 4323 } { :score 5555 } { :score 4242 } { :score -123 } { :score 330 }]} ;; EXPECTED [{ :lowest-scores [ -123 1 200 330 4242 ]}]","title":"bottom"},{"location":"bottom/#bottom","text":"An aggregate functions that returns the lowest n values for some expr across the group. In the below example we use bottom to find the lowest 5 scores for a table of Player data. ;; QUERY [[ :from :Player ] [ :agg [] [ :lowest-scores [ rel/bottom 5 :score ]]]] ;; STATE { :Player [{ :score 1 } { :score 200 } { :score 4323 } { :score 5555 } { :score 4242 } { :score -123 } { :score 330 }]} ;; EXPECTED [{ :lowest-scores [ -123 1 200 330 4242 ]}]","title":"bottom"},{"location":"btree/","text":":btree The :btree operation creates a sorted index, it is similar to :hash apart from the resulting nested-map is sorted instead of hash-ordered. Like other index operations, this is considered a tuning parameter and isn't necessary for relic to work, typically you would only materialize these to enable faster query in advanced situations, or index access to sorted indexes. :btree indexes can enable range query optimisations, such as seqing from a key in a particular order. Here is an example of indexing events by timestamp. ;; QUERY ;; you index expressions, here I am going to use a single expression, ;; but I could use multiple and get a nested map, e.g [:btree :a, :b, :c] [[ :from :Event ] [ :btree :ts ]] ;; STATE { :Event [{ :ts 0 , :msg \"hello\" } { :ts 1 , :msg \", world\" } { :ts 2 , :msg \"!\" }]} ;; INDEX ;; a sorted map, that supports subseq and rsubseq ;; get with rel/index { 0 # {{ :ts 0 , :msg \"hello\" }} 1 # {{ :ts 1 , :msg \", world\" }} 2 # {{ :ts 2 , :msg \"!\" }}}","title":":btree"},{"location":"btree/#btree","text":"The :btree operation creates a sorted index, it is similar to :hash apart from the resulting nested-map is sorted instead of hash-ordered. Like other index operations, this is considered a tuning parameter and isn't necessary for relic to work, typically you would only materialize these to enable faster query in advanced situations, or index access to sorted indexes. :btree indexes can enable range query optimisations, such as seqing from a key in a particular order. Here is an example of indexing events by timestamp. ;; QUERY ;; you index expressions, here I am going to use a single expression, ;; but I could use multiple and get a nested map, e.g [:btree :a, :b, :c] [[ :from :Event ] [ :btree :ts ]] ;; STATE { :Event [{ :ts 0 , :msg \"hello\" } { :ts 1 , :msg \", world\" } { :ts 2 , :msg \"!\" }]} ;; INDEX ;; a sorted map, that supports subseq and rsubseq ;; get with rel/index { 0 # {{ :ts 0 , :msg \"hello\" }} 1 # {{ :ts 1 , :msg \", world\" }} 2 # {{ :ts 2 , :msg \"!\" }}}","title":":btree"},{"location":"change-tracking/","text":"Change Tracking One of the key features of relic is discrete change tracking, this enables integration with other reactive or signal graph systems such as react. Any query can be watched so that you can ask what rows were added or deleted by a transaction with track-transact . ;; given a query we are interested in watching ( def ViewModel [[ :from :User ] [ :where :selected ]]) ;; lets assume the state looks like this: { :User [{ :user \"alice\" , :selected false } { :user \"bob\" , :selected false }]} ;; enable change tracking for our query with watch ;; this returns a new relic database, don't worry its totally pure! ( def db ( rel/watch db ViewModel )) ;; now we have a watched query, we can track-transact and receive changes to it. ( rel/track-transact db [ :update :User { :selected true } [ = :user \"bob\" ]]) ;; => { ;; the first key is just the :db as with the transactions applied :db { :User # {{ :user \"alice\" , :selected false } , { :user \"bob\" , :selected true }}} , ;; you also get a :changes key, which is the map of {query changes} for all watched queries :changes { ;; our watched ViewModel query from earlier [[ :from :User ] [ :where :selected ]] ;; added rows and deleted rows are returned. { :added [{ :user \"bob\" , :selected true }] , :deleted []}}} ;; you can unwatch ( def db ( rel/unwatch db ViewModel )) You can watch any query or table. To enable change tracking watch materializes queries so the same memory/performance trade-offs apply. See the cljidle demo for an example of change tracking with reagent.","title":"Change tracking"},{"location":"change-tracking/#change-tracking","text":"One of the key features of relic is discrete change tracking, this enables integration with other reactive or signal graph systems such as react. Any query can be watched so that you can ask what rows were added or deleted by a transaction with track-transact . ;; given a query we are interested in watching ( def ViewModel [[ :from :User ] [ :where :selected ]]) ;; lets assume the state looks like this: { :User [{ :user \"alice\" , :selected false } { :user \"bob\" , :selected false }]} ;; enable change tracking for our query with watch ;; this returns a new relic database, don't worry its totally pure! ( def db ( rel/watch db ViewModel )) ;; now we have a watched query, we can track-transact and receive changes to it. ( rel/track-transact db [ :update :User { :selected true } [ = :user \"bob\" ]]) ;; => { ;; the first key is just the :db as with the transactions applied :db { :User # {{ :user \"alice\" , :selected false } , { :user \"bob\" , :selected true }}} , ;; you also get a :changes key, which is the map of {query changes} for all watched queries :changes { ;; our watched ViewModel query from earlier [[ :from :User ] [ :where :selected ]] ;; added rows and deleted rows are returned. { :added [{ :user \"bob\" , :selected true }] , :deleted []}}} ;; you can unwatch ( def db ( rel/unwatch db ViewModel )) You can watch any query or table. To enable change tracking watch materializes queries so the same memory/performance trade-offs apply. See the cljidle demo for an example of change tracking with reagent.","title":"Change Tracking"},{"location":"check/","text":":check The check constraint can be used for predicative assertions on rows. You could use it as a hook for spec or malli, or some inline validation. You can either use relic expressions as a check, or a map to override error messages. [[ :from :Person ] [ :check [ string? :name ]]] ;; or a map if you want a cleaner error [[ :from :Person ] [ :check { :pred [ string? :name ] :error \"All people must have a string :name\" }]] ;; you can mix and match multiple check constraints ;; (they run left to right) [[ :from :Person ] [ :check [ string? :name ] [ nat-int? :age ]]] ;; the :error key actually takes a relic expression (or function like always!) ;; so you can get really fancy, (think malli / expound errors!) [[ :from :Person ] [ :check { :pred [ string? :name ] :error [ str \"Expected a string :name, got \" [ type :name ]]}]]","title":":check"},{"location":"check/#check","text":"The check constraint can be used for predicative assertions on rows. You could use it as a hook for spec or malli, or some inline validation. You can either use relic expressions as a check, or a map to override error messages. [[ :from :Person ] [ :check [ string? :name ]]] ;; or a map if you want a cleaner error [[ :from :Person ] [ :check { :pred [ string? :name ] :error \"All people must have a string :name\" }]] ;; you can mix and match multiple check constraints ;; (they run left to right) [[ :from :Person ] [ :check [ string? :name ] [ nat-int? :age ]]] ;; the :error key actually takes a relic expression (or function like always!) ;; so you can get really fancy, (think malli / expound errors!) [[ :from :Person ] [ :check { :pred [ string? :name ] :error [ str \"Expected a string :name, got \" [ type :name ]]}]]","title":":check"},{"location":"const/","text":":const Provides a constant collection as a relation. Probably the most boring operator, of questionable utility. Use if you want to do relic processing on known-ahead-of-time sequences of maps. [[ :const [{ :a 1 } { :a 2 } { :a 3 }]] [ :where [ even? :a ]]] ;; => [{ :a 2 }]","title":":const"},{"location":"const/#const","text":"Provides a constant collection as a relation. Probably the most boring operator, of questionable utility. Use if you want to do relic processing on known-ahead-of-time sequences of maps. [[ :const [{ :a 1 } { :a 2 } { :a 3 }]] [ :where [ even? :a ]]] ;; => [{ :a 2 }]","title":":const"},{"location":"constrain/","text":":constrain The :constrain operator allows you to compose multiple constraints in one operation for concision. This is unique among queries only because constraints run for their side effects, so fan-out and check results is a valid approach. [[ :from :Person ] [ :constrain [ :req :name ] [ :check [ string? :name ] [ nat-int? :age ]] [ :fk Address { :address-id :id }] [ :unique :email ]]] Pure sugar, otherwise unremarkable, see constraints for more detail on individual constraint operators.`","title":":constrain"},{"location":"constrain/#constrain","text":"The :constrain operator allows you to compose multiple constraints in one operation for concision. This is unique among queries only because constraints run for their side effects, so fan-out and check results is a valid approach. [[ :from :Person ] [ :constrain [ :req :name ] [ :check [ string? :name ] [ nat-int? :age ]] [ :fk Address { :address-id :id }] [ :unique :email ]]] Pure sugar, otherwise unremarkable, see constraints for more detail on individual constraint operators.`","title":":constrain"},{"location":"constraints/","text":"Constraints Constraints are just queries ending in one of the constraint statements like :unique , :fk and :check . These operators throw exceptions when the constraints are not met. You can use constraints to get confidence that databases are always in valid states, and you didn't accidentally screw something up (perhaps at dev time). To constrain a database such that you get errors when putting the db into invalid states, you materialize constraint queries (and they can be removed with demat ). Constraints can apply to any query, so you can apply constraints to aggregates and joins, here is the obligatory order can have at most 10 items if its associated customer is called bob and its tuesday constraint. [[ :from Order ] [ :join Customer { :customer-id :customer-id }] [ :where [ = \"bob\" :firstname ] [ tuesday? [ rel/env :now ]]] [ :check { :pred [ <= [ count :items ] 10 ] , :error [ str \"order can have at most 10 items if its associated customer is called bob and its tuesday, found: \" [ count :items ]]}]] As it is convenient to specify multiple constraints on a query in one form, a special :constrain operator is provided. e.g [[ :from Customer ] [ :constrain [ :check [ string? :firstname ] [ string? :lastname ] [ nat-int? :age ]] [ :unique :customer-id ] [ :fk Address { :address-id :address-id }]]] Constraint operators :check ensure certain predicates hold :req ensure cols exist :fk ensure a referenced row exists in some other query/table :constrain combine multiple constraints on a query/table :unique unsure only one row exists for some set of expressions","title":"Overview"},{"location":"constraints/#constraints","text":"Constraints are just queries ending in one of the constraint statements like :unique , :fk and :check . These operators throw exceptions when the constraints are not met. You can use constraints to get confidence that databases are always in valid states, and you didn't accidentally screw something up (perhaps at dev time). To constrain a database such that you get errors when putting the db into invalid states, you materialize constraint queries (and they can be removed with demat ). Constraints can apply to any query, so you can apply constraints to aggregates and joins, here is the obligatory order can have at most 10 items if its associated customer is called bob and its tuesday constraint. [[ :from Order ] [ :join Customer { :customer-id :customer-id }] [ :where [ = \"bob\" :firstname ] [ tuesday? [ rel/env :now ]]] [ :check { :pred [ <= [ count :items ] 10 ] , :error [ str \"order can have at most 10 items if its associated customer is called bob and its tuesday, found: \" [ count :items ]]}]] As it is convenient to specify multiple constraints on a query in one form, a special :constrain operator is provided. e.g [[ :from Customer ] [ :constrain [ :check [ string? :firstname ] [ string? :lastname ] [ nat-int? :age ]] [ :unique :customer-id ] [ :fk Address { :address-id :address-id }]]]","title":"Constraints"},{"location":"constraints/#constraint-operators","text":":check ensure certain predicates hold :req ensure cols exist :fk ensure a referenced row exists in some other query/table :constrain combine multiple constraints on a query/table :unique unsure only one row exists for some set of expressions","title":"Constraint operators"},{"location":"count-distinct/","text":"count-distinct The count distinct aggregate function can be used to count the number of unique values for some expression over a group. The below example counts the number of unique customers in the :Order table. ;; QUERY [[ :from :Order ] [ :agg [] [ :n-customers [ rel/count-distinct :customer-id ]]]] ;; STATE { :Order [{ :customer-id 42 , :order-id 0 } , { :customer-id 42 , :order-id 1 } , { :customer-id 43 , :order-id 2 }]} ;; RESULT [{ :n-customers 2 }] _","title":"count-distinct"},{"location":"count-distinct/#count-distinct","text":"The count distinct aggregate function can be used to count the number of unique values for some expression over a group. The below example counts the number of unique customers in the :Order table. ;; QUERY [[ :from :Order ] [ :agg [] [ :n-customers [ rel/count-distinct :customer-id ]]]] ;; STATE { :Order [{ :customer-id 42 , :order-id 0 } , { :customer-id 42 , :order-id 1 } , { :customer-id 43 , :order-id 2 }]} ;; RESULT [{ :n-customers 2 }] _","title":"count-distinct"},{"location":"count/","text":"count You can use clojure.core/count as an aggregate function! It does pretty much what you expect, count rows within a group. Has an optional expr argument if you want to count rows only where some predicate holds (handy!). ;; QUERY [[ :from :Order ] [ :agg [ :customer-id ] [ :number-of-orders count ] [ :number-of-refunded-orders [ count :refunded ]]]] ;; STATE { :Order [{ :customer-id 42 , :order-id 0 } , { :customer-id 42 , :order-id 1 , :refunded true }]} ;; RESULT [{ :customer-id 42 , :number-of-orders 2 , :number-of-refunded-orders 1 }]","title":"count"},{"location":"count/#count","text":"You can use clojure.core/count as an aggregate function! It does pretty much what you expect, count rows within a group. Has an optional expr argument if you want to count rows only where some predicate holds (handy!). ;; QUERY [[ :from :Order ] [ :agg [ :customer-id ] [ :number-of-orders count ] [ :number-of-refunded-orders [ count :refunded ]]]] ;; STATE { :Order [{ :customer-id 42 , :order-id 0 } , { :customer-id 42 , :order-id 1 , :refunded true }]} ;; RESULT [{ :customer-id 42 , :number-of-orders 2 , :number-of-refunded-orders 1 }]","title":"count"},{"location":"delete-exact/","text":":delete-exact Delete exact is useful when you know the exact values of the rows you want to delete, so conditions are kind of pointless. [ :delete-exact :Customer customer-row ] ;; is the same as below, but faster, and saves some typing. [ :delete :Customer [ = :% [ :_ customer-row ]]] See also :delete .","title":":delete-exact"},{"location":"delete-exact/#delete-exact","text":"Delete exact is useful when you know the exact values of the rows you want to delete, so conditions are kind of pointless. [ :delete-exact :Customer customer-row ] ;; is the same as below, but faster, and saves some typing. [ :delete :Customer [ = :% [ :_ customer-row ]]] See also :delete .","title":":delete-exact"},{"location":"delete/","text":":delete The :delete transaction form allow you delete rows by predicate expressions . In the below example, we delete rows for all people called Tom. ( rel/transact db [ :delete :Person [ = :name \"Tom\" ]]) You can supply multiple predicates ( rel/transact db [ :delete :Event [ = :type \"insert\" ] [ < :ts 1640251544389 ]]) Like other transaction forms you can only modify tables, all derived state is maintained by relic.","title":":delete"},{"location":"delete/#delete","text":"The :delete transaction form allow you delete rows by predicate expressions . In the below example, we delete rows for all people called Tom. ( rel/transact db [ :delete :Person [ = :name \"Tom\" ]]) You can supply multiple predicates ( rel/transact db [ :delete :Event [ = :type \"insert\" ] [ < :ts 1640251544389 ]]) Like other transaction forms you can only modify tables, all derived state is maintained by relic.","title":":delete"},{"location":"demos/","text":"Demo applications cljidle A clojurescript idle game. Demonstrates a minimalistic integration with reagent. view the code play in the browser","title":"Demos"},{"location":"demos/#demo-applications","text":"","title":"Demo applications"},{"location":"demos/#cljidle","text":"A clojurescript idle game. Demonstrates a minimalistic integration with reagent. view the code play in the browser","title":"cljidle"},{"location":"difference/","text":":difference Set difference, returns rows in the left relations that are not in the right. Accepts multiple tables/queries as parameters. Same kind of thing as clojure.set/difference . Examples ( def GoodCustomer [[ :from :Customer ] [ :where [ :<= 100 :score ]]]) ( def BadCustomers [[ :from :Customer ] [ :difference GoodCustomer ]])","title":":difference"},{"location":"difference/#difference","text":"Set difference, returns rows in the left relations that are not in the right. Accepts multiple tables/queries as parameters. Same kind of thing as clojure.set/difference .","title":":difference"},{"location":"difference/#examples","text":"( def GoodCustomer [[ :from :Customer ] [ :where [ :<= 100 :score ]]]) ( def BadCustomers [[ :from :Customer ] [ :difference GoodCustomer ]])","title":"Examples"},{"location":"env/","text":"The environment In relic, you are encouraged to keep all of your parameters (e.g things that might affect the result of a query that are not part of the query definition itself) in tables. However, in real programs we treat many parameters as globals in practice, such as the current time, or the value of an environment variable. In relic the 'environment' is a special table designed to hold global parameters, which comes with some sugar to make working with things like time a bit easier. ;; replaces the environment with the given map, returning a new db ( rel/with-env db { :now ( System/currentTimeMillis )}) ;; you can reference the environment in queries with the Frel/env special expression form [[ :select [ :seconds [ / [ rel/env :now ] 1000 ]]] ;; get the env map ( rel/get-env db ) ;; => { :now 1640787329215 } ;; apply a fn to the env map ( rel/update-env db assoc :now ( System/currentTimeMillis )) As with other tables, you want to only store essential state. So in the case of time, your env may hold the raw ms time, and you could then derive views for various different local times, projections, datatypes etc that your queries can use. ( defn instant [ ms ] ( Instant/ofEpohMilli ms )) ( defn local-date-time [ instant zone ] ( LocalDateTime/ofInstant instant ( ZoneId/of zone ))) ( def Time [[ :select [ :time/epoch-ms [ rel/env :now ]] [ :time/instant [ instant :time/epoch-ms ]] [ :time/london [ local-date-time :time/instant \"Europe/London\" ]]])","title":"Environment"},{"location":"env/#the-environment","text":"In relic, you are encouraged to keep all of your parameters (e.g things that might affect the result of a query that are not part of the query definition itself) in tables. However, in real programs we treat many parameters as globals in practice, such as the current time, or the value of an environment variable. In relic the 'environment' is a special table designed to hold global parameters, which comes with some sugar to make working with things like time a bit easier. ;; replaces the environment with the given map, returning a new db ( rel/with-env db { :now ( System/currentTimeMillis )}) ;; you can reference the environment in queries with the Frel/env special expression form [[ :select [ :seconds [ / [ rel/env :now ] 1000 ]]] ;; get the env map ( rel/get-env db ) ;; => { :now 1640787329215 } ;; apply a fn to the env map ( rel/update-env db assoc :now ( System/currentTimeMillis )) As with other tables, you want to only store essential state. So in the case of time, your env may hold the raw ms time, and you could then derive views for various different local times, projections, datatypes etc that your queries can use. ( defn instant [ ms ] ( Instant/ofEpohMilli ms )) ( defn local-date-time [ instant zone ] ( LocalDateTime/ofInstant instant ( ZoneId/of zone ))) ( def Time [[ :select [ :time/epoch-ms [ rel/env :now ]] [ :time/instant [ instant :time/epoch-ms ]] [ :time/london [ local-date-time :time/instant \"Europe/London\" ]]])","title":"The environment"},{"location":"expand/","text":":expand Provides a means of flattening trees, that is you might start your relational data with nested (document) style maps, and you want to de-nest to make nested data accessible via joins. Examples ;; In this example, Order contains nested 'order' maps with an :items collection. ( rel/q db Order ) ;; => # {{ :customer-id 42 , :items [{ :product 1 , :quantity 2 } , { :product 2 , :quantity 1 }]}} ;; I want to see OrderItems as their own relation, so I :expand them. ( def OrderItem [[ :from :Order ] [ :expand [[ :product :quantity ] :items ]] [ :without :items ]]) ;; You can see the expansion columns are included along with the order header columns. ( rel/q db OrderItem ) ;; => # {{ :customer-id 42 , :product 1 , :quantity 2 } , { :customer-id 42 , :product 2 , :quantity 1 }}","title":":expand"},{"location":"expand/#expand","text":"Provides a means of flattening trees, that is you might start your relational data with nested (document) style maps, and you want to de-nest to make nested data accessible via joins.","title":":expand"},{"location":"expand/#examples","text":";; In this example, Order contains nested 'order' maps with an :items collection. ( rel/q db Order ) ;; => # {{ :customer-id 42 , :items [{ :product 1 , :quantity 2 } , { :product 2 , :quantity 1 }]}} ;; I want to see OrderItems as their own relation, so I :expand them. ( def OrderItem [[ :from :Order ] [ :expand [[ :product :quantity ] :items ]] [ :without :items ]]) ;; You can see the expansion columns are included along with the order header columns. ( rel/q db OrderItem ) ;; => # {{ :customer-id 42 , :product 1 , :quantity 2 } , { :customer-id 42 , :product 2 , :quantity 1 }}","title":"Examples"},{"location":"expr/","text":"Expressions As relic supports conditions and computation via various query operations, it needs to support a form of computation expression. Your options are: use clojure functions use relic expressions Where you can use expressions: :where conditions :extend extensions :select projections :expand expansions :join / :left-join clauses :agg certain aggregates accept expressions as args (e.g sum ) :hash indexed expressions :btree indexed expressions clojure functions Clojure functions are fully supported by relic, and it is a major design goal to be able to drop to Clojure to do arbitrary ( pure! ) computation. n.b functions must be referentially transparent, or you risk glitches ;; you can use any function as an expression ( defn my-pred? [{ :keys [ foo ]}] ( = foo 42 )) [[ :from :A ] [ :where my-pred? ]] ;; same rules apply to computing columns ( defn compute-bar [{ :keys [ foo ]}] ( inc foo )) [[ :from :A ] [ :extend [ :bar compute-bar ]] [[ :from :A ] [ :select [ :bar compute-bar ]] ;; and expansions ( defn compute-baz-seq [{ :keys [ foo ]}] ( range foo )) [[ :from :A ] [ :expand [ :baz compute-baz-seq ]] relic expressions For convenience, and some extra goodies - an expression dsl is provided that lets you do simple computations 'inline', provides better ergonmics as you are working with rows 100% of the time, and allows for some extra goodies like sub queries, nil safe function application and so on. Mostly the execution semantics are similar to clojure, but vectors are used for calls over lists, and keywords are substituted for lookups. The goal is to avoid quote/unquote template shenanigans, and help make programming relic easier for simple cases that don't need a unique clojure function. ;; calls are vectors, `:foo` will be substituted with `(:foo row)` [[ :from :A ] [ = :foo 42 ]] ;; non-functions/non-keywords/non-vectors are just treated as constants [[ :from :A ] [ :where true ]] ;; bare keywords are tested against the row `(:foo row)` [[ :from :A ] [ :where :foo ]] ;; expressions can nest [[ :from :A ] [ :where [ = 42 [ inc [ dec :foo ]]]]] ;; special conditional forms are provided [[ :from :A ] [ :select [ :msg [ :if [ = 42 :foo ] \"the answer\" \"not the answer\" ]]]] [[ :from :A ] [ :where [ :and :foo :bar ]]] [[ :from :A ] [ :where [ :or :foo :bar ]]] ;; you can get the row with :% [[ :from :A ] [ = 10 [ count :% ]]] ;; you can reference non-keyword keys with ::rel/get [[ :from :A ] [ :where [ ::rel/get \"foo\" ]]] ;; you can escape vectors / keywords with :_ [[ :from :A ] [ :where [ = [ :_ :bar ] :foo ]]] ;; you can reference the env (see env.md) [[ :from :A ] [ :where [ = :foo [ rel/env :foo ]]]] ;; you can issue sub queries with rel/sel1 (first row) and rel/sel (all rows) (see sub-queries.md) [[ :from :A ] [ :where [ rel/sel1 :B { :a-id :a-id }]]] ;; nil safe calls with :?, which will check all column arguments are non-nil before applying the function ;; (returning nil if any dependent col is nil) [[ :from :A ] [ :where [ :? str/includes? :foo :bar ]]] ;; comparison functions are overwritten by in relic expressions to use comparables ;; this causes btree index optimised queries to have consistent behaviour with non-indexed queries. ;; e.g the below will work [[ :from :A ] [ :where [ < :foo \"abc\" ]]] [[ :from :A ] [ :where [ >= :bar 42 ]]] [[ :from :A ] [ :where [ <= :baz # inst \"2022-01-13\" ]]]","title":"Expressions"},{"location":"expr/#expressions","text":"As relic supports conditions and computation via various query operations, it needs to support a form of computation expression. Your options are: use clojure functions use relic expressions Where you can use expressions: :where conditions :extend extensions :select projections :expand expansions :join / :left-join clauses :agg certain aggregates accept expressions as args (e.g sum ) :hash indexed expressions :btree indexed expressions","title":"Expressions"},{"location":"expr/#clojure-functions","text":"Clojure functions are fully supported by relic, and it is a major design goal to be able to drop to Clojure to do arbitrary ( pure! ) computation. n.b functions must be referentially transparent, or you risk glitches ;; you can use any function as an expression ( defn my-pred? [{ :keys [ foo ]}] ( = foo 42 )) [[ :from :A ] [ :where my-pred? ]] ;; same rules apply to computing columns ( defn compute-bar [{ :keys [ foo ]}] ( inc foo )) [[ :from :A ] [ :extend [ :bar compute-bar ]] [[ :from :A ] [ :select [ :bar compute-bar ]] ;; and expansions ( defn compute-baz-seq [{ :keys [ foo ]}] ( range foo )) [[ :from :A ] [ :expand [ :baz compute-baz-seq ]]","title":"clojure functions"},{"location":"expr/#relic-expressions","text":"For convenience, and some extra goodies - an expression dsl is provided that lets you do simple computations 'inline', provides better ergonmics as you are working with rows 100% of the time, and allows for some extra goodies like sub queries, nil safe function application and so on. Mostly the execution semantics are similar to clojure, but vectors are used for calls over lists, and keywords are substituted for lookups. The goal is to avoid quote/unquote template shenanigans, and help make programming relic easier for simple cases that don't need a unique clojure function. ;; calls are vectors, `:foo` will be substituted with `(:foo row)` [[ :from :A ] [ = :foo 42 ]] ;; non-functions/non-keywords/non-vectors are just treated as constants [[ :from :A ] [ :where true ]] ;; bare keywords are tested against the row `(:foo row)` [[ :from :A ] [ :where :foo ]] ;; expressions can nest [[ :from :A ] [ :where [ = 42 [ inc [ dec :foo ]]]]] ;; special conditional forms are provided [[ :from :A ] [ :select [ :msg [ :if [ = 42 :foo ] \"the answer\" \"not the answer\" ]]]] [[ :from :A ] [ :where [ :and :foo :bar ]]] [[ :from :A ] [ :where [ :or :foo :bar ]]] ;; you can get the row with :% [[ :from :A ] [ = 10 [ count :% ]]] ;; you can reference non-keyword keys with ::rel/get [[ :from :A ] [ :where [ ::rel/get \"foo\" ]]] ;; you can escape vectors / keywords with :_ [[ :from :A ] [ :where [ = [ :_ :bar ] :foo ]]] ;; you can reference the env (see env.md) [[ :from :A ] [ :where [ = :foo [ rel/env :foo ]]]] ;; you can issue sub queries with rel/sel1 (first row) and rel/sel (all rows) (see sub-queries.md) [[ :from :A ] [ :where [ rel/sel1 :B { :a-id :a-id }]]] ;; nil safe calls with :?, which will check all column arguments are non-nil before applying the function ;; (returning nil if any dependent col is nil) [[ :from :A ] [ :where [ :? str/includes? :foo :bar ]]] ;; comparison functions are overwritten by in relic expressions to use comparables ;; this causes btree index optimised queries to have consistent behaviour with non-indexed queries. ;; e.g the below will work [[ :from :A ] [ :where [ < :foo \"abc\" ]]] [[ :from :A ] [ :where [ >= :bar 42 ]]] [[ :from :A ] [ :where [ <= :baz # inst \"2022-01-13\" ]]]","title":"relic expressions"},{"location":"extend/","text":":extend Computes new columns by binding the results of expressions . If the binding collides with an existing column, the existing column is overwritten. Accepts multiple extension forms, each a pair [binding expr] . The binding determines how the result should be added to the row: a column (keyword), just overwrite or add the column to the row a collection, assume the result is a map, and select-keys the collection and merge into the row. the special keyword :* , merge the entire result into the row. Form extend = [ :extend & extension ] extension = [ binding expr ] binding = col | [ & col ] | :* See expression reference for more information on expressions. Examples [[ :from :Customer ] [ :extend [ :fullname [ str :firstname \" \" :lastname ]]]] ( def TotalSpend [[ :from :Order ] [ :agg [ :customer-id ] [ :total-spend [ rel/sum :total ]]]]) Sub queries with rel/sel1 and rel/sel ;; rel/sel1 to sub select another row, i.e an implicit left-join. ( def CustomerStats [[ :from :Customer ] [ :extend [[ :total-spend ] [ rel/sel1 TotalSpend { :customer-id :customer-id }]]]]) ;; would result in a relation something like: # {{ :customer 42 , :total-spend 340.0 M }} ;; rel/sel to bind rows from another query to a column ( def Order [[ :from :Order ] [ :extend [ :items [ rel/sel OrderItem { :order-id :order-id }]]]]) ;; would result in a relation something like: # {{ :customer-id 42 , :total 340.0 M :items # {{ :product-id 43 , :quantity 1 } ... }} See also :select :agg","title":":extend"},{"location":"extend/#extend","text":"Computes new columns by binding the results of expressions . If the binding collides with an existing column, the existing column is overwritten. Accepts multiple extension forms, each a pair [binding expr] . The binding determines how the result should be added to the row: a column (keyword), just overwrite or add the column to the row a collection, assume the result is a map, and select-keys the collection and merge into the row. the special keyword :* , merge the entire result into the row.","title":":extend"},{"location":"extend/#form","text":"extend = [ :extend & extension ] extension = [ binding expr ] binding = col | [ & col ] | :* See expression reference for more information on expressions.","title":"Form"},{"location":"extend/#examples","text":"[[ :from :Customer ] [ :extend [ :fullname [ str :firstname \" \" :lastname ]]]] ( def TotalSpend [[ :from :Order ] [ :agg [ :customer-id ] [ :total-spend [ rel/sum :total ]]]]) Sub queries with rel/sel1 and rel/sel ;; rel/sel1 to sub select another row, i.e an implicit left-join. ( def CustomerStats [[ :from :Customer ] [ :extend [[ :total-spend ] [ rel/sel1 TotalSpend { :customer-id :customer-id }]]]]) ;; would result in a relation something like: # {{ :customer 42 , :total-spend 340.0 M }} ;; rel/sel to bind rows from another query to a column ( def Order [[ :from :Order ] [ :extend [ :items [ rel/sel OrderItem { :order-id :order-id }]]]]) ;; would result in a relation something like: # {{ :customer-id 42 , :total 340.0 M :items # {{ :product-id 43 , :quantity 1 } ... }}","title":"Examples"},{"location":"extend/#see-also","text":":select :agg","title":"See also"},{"location":"extension/","text":"Extension Currently it is not recommended implementing in user programs new aggregation functions or data flow nodes. This is because the SPI for these is under consideration and not final. There are no protocols or mechanism for extension other than internals which I'd rather remained implementation detail for now. If you want relic to do something new, raise a PR for discussion and it can be implemented in relic.","title":"Extension"},{"location":"extension/#extension","text":"Currently it is not recommended implementing in user programs new aggregation functions or data flow nodes. This is because the SPI for these is under consideration and not final. There are no protocols or mechanism for extension other than internals which I'd rather remained implementation detail for now. If you want relic to do something new, raise a PR for discussion and it can be implemented in relic.","title":"Extension"},{"location":"fk/","text":":fk The foreign key constraint allows you to ensure referenced rows always exist. Like other constraints , :fk can be applied to any query, not just tables. ( def OrderMustReferToACustomer [[ :from :Order ] [ :fk :Customer { :customer-id :customer-id }]]) ( def db ( rel/mat {} OrderMustReferToACustomer )) ;; this is fine ( rel/transact db [ :insert :Customer { :customer-id 42 }] [ :insert :Order { :customer-id 42 }]) ;; this is also fine, you can insert out-of-order. ( rel/transact db [ :insert :Order { :customer-id 42 }] [ :insert :Customer { :customer-id 42 }]) ;; BOOM! Foreign key violation ( rel/transact db [ :insert :Order { :customer-id \"woops\" }]) Cascading deletes Like in SQL you can specify a :cascade option to unwind references that are invalidated by transactions. The below example would cause :Order rows to be themselves be deleted if a transaction deletes the customers they point to. [[ :from :Order ] [ :fk :Customer { :customer-id :customer-id } { :cascade :delete }]] :cascade only works if the left-side is a table (at the moment!).","title":":fk"},{"location":"fk/#fk","text":"The foreign key constraint allows you to ensure referenced rows always exist. Like other constraints , :fk can be applied to any query, not just tables. ( def OrderMustReferToACustomer [[ :from :Order ] [ :fk :Customer { :customer-id :customer-id }]]) ( def db ( rel/mat {} OrderMustReferToACustomer )) ;; this is fine ( rel/transact db [ :insert :Customer { :customer-id 42 }] [ :insert :Order { :customer-id 42 }]) ;; this is also fine, you can insert out-of-order. ( rel/transact db [ :insert :Order { :customer-id 42 }] [ :insert :Customer { :customer-id 42 }]) ;; BOOM! Foreign key violation ( rel/transact db [ :insert :Order { :customer-id \"woops\" }])","title":":fk"},{"location":"fk/#cascading-deletes","text":"Like in SQL you can specify a :cascade option to unwind references that are invalidated by transactions. The below example would cause :Order rows to be themselves be deleted if a transaction deletes the customers they point to. [[ :from :Order ] [ :fk :Customer { :customer-id :customer-id } { :cascade :delete }]] :cascade only works if the left-side is a table (at the moment!).","title":"Cascading deletes"},{"location":"from/","text":":from :from is an operation of 1-arg, either a query or keyword (table), it performs no computation, and just flows rows from its argument to the next operation in the query. ;; from a table [[ :from :A ]] ;; from another query [[ :from [[ :from :B ] [ :where [ = :foo 42 ]]]]]","title":":from"},{"location":"from/#from","text":":from is an operation of 1-arg, either a query or keyword (table), it performs no computation, and just flows rows from its argument to the next operation in the query. ;; from a table [[ :from :A ]] ;; from another query [[ :from [[ :from :B ] [ :where [ = :foo 42 ]]]]]","title":":from"},{"location":"hash/","text":":hash The :hash operation creates a hash index. Like other index operations this is considered a tuning parameter and isn't necessary for relic to work, typically you would only materialize these to enable faster query in advanced situations, or index access. Hash indexes can enable faster equality checks. They are used by default for :join and :left-join implicit indexes, you should not need to create them yourself. Here is an example of indexing customers by name. ;; QUERY ;; you index expressions, here I am going to use a single expression, ;; but I could use multiple and get a nested map, e.g [:hash :a, :b, :c] [[ :from :Customer ] [ :hash :name ]] ;; STATE { :Customer [{ :name \"bob\" , :age 42 } { :name \"alice\" , :age 23 }]} ;; INDEX ;; a clojure map ;; get with rel/index { \"bob\" # {{ :name \"bob\" , :age 42 }} \"alice\" # {{ :name \"alice\" , :age 23 }}}","title":":hash"},{"location":"hash/#hash","text":"The :hash operation creates a hash index. Like other index operations this is considered a tuning parameter and isn't necessary for relic to work, typically you would only materialize these to enable faster query in advanced situations, or index access. Hash indexes can enable faster equality checks. They are used by default for :join and :left-join implicit indexes, you should not need to create them yourself. Here is an example of indexing customers by name. ;; QUERY ;; you index expressions, here I am going to use a single expression, ;; but I could use multiple and get a nested map, e.g [:hash :a, :b, :c] [[ :from :Customer ] [ :hash :name ]] ;; STATE { :Customer [{ :name \"bob\" , :age 42 } { :name \"alice\" , :age 23 }]} ;; INDEX ;; a clojure map ;; get with rel/index { \"bob\" # {{ :name \"bob\" , :age 42 }} \"alice\" # {{ :name \"alice\" , :age 23 }}}","title":":hash"},{"location":"indexes/","text":"Indexes Relic allows you to materialize indexes to enable certain query optimisations and to allow for direct index access for specialised high-performance work. :hash nested hash map :btree nested sorted map :unique nested hash map that only allows 1 row per key You shouldn't need to worry about indexes most of the time, as relic creates them for you for operations that really need them such as :join , :left-join and :fk .","title":"Overview"},{"location":"indexes/#indexes","text":"Relic allows you to materialize indexes to enable certain query optimisations and to allow for direct index access for specialised high-performance work. :hash nested hash map :btree nested sorted map :unique nested hash map that only allows 1 row per key You shouldn't need to worry about indexes most of the time, as relic creates them for you for operations that really need them such as :join , :left-join and :fk .","title":"Indexes"},{"location":"insert-ignore/","text":":insert-ignore The :insert-ignore transact form allow you to insert rows, but on :unique key conflict, discard the new row and keep the old. ( def db ( rel/mat {} [[ :from :Customer ] [ :unique :id ]])) ;; if there is no conflict, its just insert ( def db ( rel/transact db [ :insert-ignore :Customer { :id 42 , :name \"bob\" , :age 33 }}])) ;; => { :Customer # {{ :id 42 , :name \"bob\" , :age 33 }}} ;; with a conflict, the new row will be discarded. ( rel/transact db [ :insert-ignore :Customer { :id 42 , :name \"alice\" }]) ;; => { :Customer # {{ :id 42 , :name \"bob\" , :age 33 }}} See also :insert-or-merge , :insert-or-replace , :insert-or-update , :update .","title":":insert-ignore"},{"location":"insert-ignore/#insert-ignore","text":"The :insert-ignore transact form allow you to insert rows, but on :unique key conflict, discard the new row and keep the old. ( def db ( rel/mat {} [[ :from :Customer ] [ :unique :id ]])) ;; if there is no conflict, its just insert ( def db ( rel/transact db [ :insert-ignore :Customer { :id 42 , :name \"bob\" , :age 33 }}])) ;; => { :Customer # {{ :id 42 , :name \"bob\" , :age 33 }}} ;; with a conflict, the new row will be discarded. ( rel/transact db [ :insert-ignore :Customer { :id 42 , :name \"alice\" }]) ;; => { :Customer # {{ :id 42 , :name \"bob\" , :age 33 }}} See also :insert-or-merge , :insert-or-replace , :insert-or-update , :update .","title":":insert-ignore"},{"location":"insert-or-merge/","text":":insert-or-merge The :insert-or-merge transact form is used when you want to insert rows, but on :unique key conflict, instead merge the new row into the old one. Takes a binding form that lets you specialise which cols you want to merge. ;; I want to merge by-id. ( def db ( rel/mat {} [[ :from :Customer ] [ :unique :id ]]) ;; lets insert a customer, if you do not have a conflict, this is the ;; same as insert ( def db ( rel/transact db [ :insert-or-merge :Customer :* { :id 42 , :name \"bob\" }])) ;; => { :Customer # {{ :id 42 , :name \"bob\" }}} ;; lets insert again with a conflict ;; the :* binding means, merge 'all' columns from the new row into the old one ;; you could use a vector to be selective. ( rel/transact db [ :insert-or-merge :Customer :* { :id 42 , :age 33 }]) ;; => { :Customer # {{ :id 42 , :name \"bob\" , :age 33 }}} See also :insert-or-replace , :insert-or-update . binding :* all cols [col1, col2..] a subset of cols","title":":insert-or-merge"},{"location":"insert-or-merge/#insert-or-merge","text":"The :insert-or-merge transact form is used when you want to insert rows, but on :unique key conflict, instead merge the new row into the old one. Takes a binding form that lets you specialise which cols you want to merge. ;; I want to merge by-id. ( def db ( rel/mat {} [[ :from :Customer ] [ :unique :id ]]) ;; lets insert a customer, if you do not have a conflict, this is the ;; same as insert ( def db ( rel/transact db [ :insert-or-merge :Customer :* { :id 42 , :name \"bob\" }])) ;; => { :Customer # {{ :id 42 , :name \"bob\" }}} ;; lets insert again with a conflict ;; the :* binding means, merge 'all' columns from the new row into the old one ;; you could use a vector to be selective. ( rel/transact db [ :insert-or-merge :Customer :* { :id 42 , :age 33 }]) ;; => { :Customer # {{ :id 42 , :name \"bob\" , :age 33 }}} See also :insert-or-replace , :insert-or-update .","title":":insert-or-merge"},{"location":"insert-or-merge/#binding","text":":* all cols [col1, col2..] a subset of cols","title":"binding"},{"location":"insert-or-replace/","text":":insert-or-replace The :insert-or-replace transact form allow you to insert rows, but on :unique key conflict, replace the old row with the new one. ( def db ( rel/mat {} [[ :from :Customer ] [ :unique :id ]])) ;; if there is no conflict, its just insert ( def db ( rel/transact db [ :insert-or-replace :Customer { :id 42 , :name \"bob\" , :age 33 }}])) ;; => { :Customer # {{ :id 42 , :name \"bob\" , :age 33 }}} ;; with a conflict, the whole row will be replaced - we will change the name, and ;; drop :age. ( rel/transact db [ :insert-or-replace :Customer { :id 42 , :name \"alice\" }]) ;; => { :Customer # {{ :id 42 , :name \"alice\" }}} See also :insert-or-merge , :insert-or-update .","title":":insert-or-replace"},{"location":"insert-or-replace/#insert-or-replace","text":"The :insert-or-replace transact form allow you to insert rows, but on :unique key conflict, replace the old row with the new one. ( def db ( rel/mat {} [[ :from :Customer ] [ :unique :id ]])) ;; if there is no conflict, its just insert ( def db ( rel/transact db [ :insert-or-replace :Customer { :id 42 , :name \"bob\" , :age 33 }}])) ;; => { :Customer # {{ :id 42 , :name \"bob\" , :age 33 }}} ;; with a conflict, the whole row will be replaced - we will change the name, and ;; drop :age. ( rel/transact db [ :insert-or-replace :Customer { :id 42 , :name \"alice\" }]) ;; => { :Customer # {{ :id 42 , :name \"alice\" }}} See also :insert-or-merge , :insert-or-update .","title":":insert-or-replace"},{"location":"insert-or-update/","text":":insert-or-update The :insert-or-update transact form allow you to insert rows, but on :unique key conflict, apply a function (or SQL style update map ) to the old row instead. ( def db ( rel/mat {} [[ :from :Customer ] [ :unique :id ]])) ;; if there is no conflict, its just insert ( def db ( rel/transact db [ :insert-or-update :Customer { :updates [ inc [ :or :updates 0 ]]} { :id 42 , :name \"bob\" , :age 33 }}])) ;; => { :Customer # {{ :id 42 , :name \"bob\" , :age 33 }}} ;; with a conflict, the function (or set map) will be applied to the OLD row, and the new row will be discarded. ( rel/transact db [ :insert-or-replace :Customer { :updates [ inc [ :or :updates 0 ]]} { :id 42 , :name \"alice\" }]) ;; => { :Customer # {{ :id 42 , :name \"bob\" , :age 33 , :updates 1 }}} See also :insert-or-merge , :insert-or-replace , :update .","title":":insert-or-update"},{"location":"insert-or-update/#insert-or-update","text":"The :insert-or-update transact form allow you to insert rows, but on :unique key conflict, apply a function (or SQL style update map ) to the old row instead. ( def db ( rel/mat {} [[ :from :Customer ] [ :unique :id ]])) ;; if there is no conflict, its just insert ( def db ( rel/transact db [ :insert-or-update :Customer { :updates [ inc [ :or :updates 0 ]]} { :id 42 , :name \"bob\" , :age 33 }}])) ;; => { :Customer # {{ :id 42 , :name \"bob\" , :age 33 }}} ;; with a conflict, the function (or set map) will be applied to the OLD row, and the new row will be discarded. ( rel/transact db [ :insert-or-replace :Customer { :updates [ inc [ :or :updates 0 ]]} { :id 42 , :name \"alice\" }]) ;; => { :Customer # {{ :id 42 , :name \"bob\" , :age 33 , :updates 1 }}} See also :insert-or-merge , :insert-or-replace , :update .","title":":insert-or-update"},{"location":"insert/","text":":insert The :insert transact form is how you add rows to tables. Like other transact forms, it can throw exceptions if constraints are violated. ( def db {}) ( rel/transact db [ :insert :Food { :name \"pizza\" } , { :name \"pie\" }]) ;; => { :Food # {{ :name \"pizza\" } , { :name \"pie\" }}} See also terser insert , :insert-or-replace , :insert-or-merge , :insert-or-update .","title":":insert"},{"location":"insert/#insert","text":"The :insert transact form is how you add rows to tables. Like other transact forms, it can throw exceptions if constraints are violated. ( def db {}) ( rel/transact db [ :insert :Food { :name \"pizza\" } , { :name \"pie\" }]) ;; => { :Food # {{ :name \"pizza\" } , { :name \"pie\" }}} See also terser insert , :insert-or-replace , :insert-or-merge , :insert-or-update .","title":":insert"},{"location":"intersection/","text":":intersection Set intersection, returns rows in the left relations that are also in each right relation. Accepts multiple tables/queries as parameters. Same kind of thing as clojure.set/intersection . Examples ( def GoodCustomer [[ :from :Customer ] [ :where [ :<= 100 :score ]]]) ( def John [[ :from :Customer ] [ :where [ = :firstname \"John\" ]]]) ( def GoodJohn [[ :from GoodCustomer ] [ :intersection John ]])","title":":intersection"},{"location":"intersection/#intersection","text":"Set intersection, returns rows in the left relations that are also in each right relation. Accepts multiple tables/queries as parameters. Same kind of thing as clojure.set/intersection .","title":":intersection"},{"location":"intersection/#examples","text":"( def GoodCustomer [[ :from :Customer ] [ :where [ :<= 100 :score ]]]) ( def John [[ :from :Customer ] [ :where [ = :firstname \"John\" ]]]) ( def GoodJohn [[ :from GoodCustomer ] [ :intersection John ]])","title":"Examples"},{"location":"join/","text":":join Joins relations together, returning the product of matching rows. The columns in the relation on the right will be preferred in a conflict. Like set/join , clause is a map of expressions on the left to expressions on the right. Accepts both tables (keywords) and other queries. Similar to an INNER JOIN in SQL. Form join = [ :join right clause & more ] right = query | table clause = { left-expr right-expr , ... } Examples [[ :from :Customer ] [ :join :Order { :id :customer-id }]]","title":":join"},{"location":"join/#join","text":"Joins relations together, returning the product of matching rows. The columns in the relation on the right will be preferred in a conflict. Like set/join , clause is a map of expressions on the left to expressions on the right. Accepts both tables (keywords) and other queries. Similar to an INNER JOIN in SQL.","title":":join"},{"location":"join/#form","text":"join = [ :join right clause & more ] right = query | table clause = { left-expr right-expr , ... }","title":"Form"},{"location":"join/#examples","text":"[[ :from :Customer ] [ :join :Order { :id :customer-id }]]","title":"Examples"},{"location":"left-join/","text":":left-join Like join but returns rows even if there are no matches in the right relation. Like SQL LEFT JOIN . Form left-join = [ :left-join right clause & more ] right = query | table clause = { left-expr right-expr , ... } Examples [[ :from :Customer ] ;; if orders are missing, you will get customer rows on their own [ :left-join :Order { :id :customer-id }]]","title":":left-join"},{"location":"left-join/#left-join","text":"Like join but returns rows even if there are no matches in the right relation. Like SQL LEFT JOIN .","title":":left-join"},{"location":"left-join/#form","text":"left-join = [ :left-join right clause & more ] right = query | table clause = { left-expr right-expr , ... }","title":"Form"},{"location":"left-join/#examples","text":"[[ :from :Customer ] ;; if orders are missing, you will get customer rows on their own [ :left-join :Order { :id :customer-id }]]","title":"Examples"},{"location":"lookup/","text":":lookup The :lookup operation is used for queries against indexes , when you need to be explicit. One thing to know about :lookup is you cannot mat it, it is fairly unique in that regard. ( def CustomerByName [[ :from :Customer ] [ :hash :firstname ]]) ( def db ( rel/mat {} CustomerByName )) ( def db ( rel/transact {} [ :insert :Customer { :firstname \"bob\" }])) ( rel/q db [[ :lookup CustomerByName \"bob\" ]]) ;; => ({ :firstname \"bob\" })","title":":lookup"},{"location":"lookup/#lookup","text":"The :lookup operation is used for queries against indexes , when you need to be explicit. One thing to know about :lookup is you cannot mat it, it is fairly unique in that regard. ( def CustomerByName [[ :from :Customer ] [ :hash :firstname ]]) ( def db ( rel/mat {} CustomerByName )) ( def db ( rel/transact {} [ :insert :Customer { :firstname \"bob\" }])) ( rel/q db [[ :lookup CustomerByName \"bob\" ]]) ;; => ({ :firstname \"bob\" })","title":":lookup"},{"location":"materialization/","text":"Materialization One of the key value propositions of relic, or at least a major super-power is the ability to materialize ( mat ) queries. By materializing a query, the results are cached, and further more transactions that would change the results automatically invalidate the cache. relic does this incrementally, it knows how to flow only necessary changes, and minimize the work done on change by using a bunch of different internal indexes. It means you can have aggregations over multiple joined tables in your reagent application for example without any custom data structures or custom code to maintain the various indexes and structures that would be necessary to incrementally compute it. ;; a query like this can change when segments change for orders, orders are changed. ;; relic will know how to change the sum without recomputing the whole query, it does this with a custom index for the sum that allows ;; relic not to re-sum rows that haven't been touched. ( rel/mat db [[ :from :Order ] [ :join CustomerSegment { :customer-id :customer-id }] [ :agg [ :segment ] [ :revenue [ rel/sum :total ]]]]) As you are trading memory for time by materializing queries, you might want to dematerialize them. (rel/demat db query) See also: constraints , change tracking , query .","title":"Materialization"},{"location":"materialization/#materialization","text":"One of the key value propositions of relic, or at least a major super-power is the ability to materialize ( mat ) queries. By materializing a query, the results are cached, and further more transactions that would change the results automatically invalidate the cache. relic does this incrementally, it knows how to flow only necessary changes, and minimize the work done on change by using a bunch of different internal indexes. It means you can have aggregations over multiple joined tables in your reagent application for example without any custom data structures or custom code to maintain the various indexes and structures that would be necessary to incrementally compute it. ;; a query like this can change when segments change for orders, orders are changed. ;; relic will know how to change the sum without recomputing the whole query, it does this with a custom index for the sum that allows ;; relic not to re-sum rows that haven't been touched. ( rel/mat db [[ :from :Order ] [ :join CustomerSegment { :customer-id :customer-id }] [ :agg [ :segment ] [ :revenue [ rel/sum :total ]]]]) As you are trading memory for time by materializing queries, you might want to dematerialize them. (rel/demat db query) See also: constraints , change tracking , query .","title":"Materialization"},{"location":"max-by/","text":"max-by The max-by aggregate function allows you to find the row with some highest value across a set of rows. In this example, we get the row having the maximum :id across the entire :Customer table. ;; QUERY [[ :from :Customer ] [ :agg [] [ :max-id-row [ rel/max-by :id ]]]] ;; STATE { :Customer # {{ :id 0 } , { :id 1 } , { :id 2 }}} ;; RESULT ({ :max-id-row { :id 2 }})","title":"max-by"},{"location":"max-by/#max-by","text":"The max-by aggregate function allows you to find the row with some highest value across a set of rows. In this example, we get the row having the maximum :id across the entire :Customer table. ;; QUERY [[ :from :Customer ] [ :agg [] [ :max-id-row [ rel/max-by :id ]]]] ;; STATE { :Customer # {{ :id 0 } , { :id 1 } , { :id 2 }}} ;; RESULT ({ :max-id-row { :id 2 }})","title":"max-by"},{"location":"max/","text":"max The max aggregate function allows you to find the highest value across a set of rows. In this example, we take the maximum :id across the entire :Customer table. ;; QUERY [[ :from :Customer ] [ :agg [] [ :max-id [ max :id ]]]] ;; STATE { :Customer # {{ :id 0 } , { :id 1 } , { :id 2 }}} ;; RESULT ({ :max-id 2 })","title":"max"},{"location":"max/#max","text":"The max aggregate function allows you to find the highest value across a set of rows. In this example, we take the maximum :id across the entire :Customer table. ;; QUERY [[ :from :Customer ] [ :agg [] [ :max-id [ max :id ]]]] ;; STATE { :Customer # {{ :id 0 } , { :id 1 } , { :id 2 }}} ;; RESULT ({ :max-id 2 })","title":"max"},{"location":"min-by/","text":"min-by The min-by aggregate function allows you to find the row with some lowest value across a set of rows. In this example, we get the row having the minimum :id across the entire :Customer table. ;; QUERY [[ :from :Customer ] [ :agg [] [ :min-id-row [ rel/min-by :id ]]]] ;; STATE { :Customer # {{ :id 0 } , { :id 1 } , { :id 2 }}} ;; RESULT ({ :min-id-row { :id 0 }})","title":"min-by"},{"location":"min-by/#min-by","text":"The min-by aggregate function allows you to find the row with some lowest value across a set of rows. In this example, we get the row having the minimum :id across the entire :Customer table. ;; QUERY [[ :from :Customer ] [ :agg [] [ :min-id-row [ rel/min-by :id ]]]] ;; STATE { :Customer # {{ :id 0 } , { :id 1 } , { :id 2 }}} ;; RESULT ({ :min-id-row { :id 0 }})","title":"min-by"},{"location":"min/","text":"min The min aggregate function allows you to find the lowest value across a set of rows. In this example, we take the minimum :id across the entire :Customer table. ;; QUERY [[ :from :Customer ] [ :agg [] [ :min-id [ min :id ]]]] ;; STATE { :Customer # {{ :id 0 } , { :id 1 } , { :id 2 }}} ;; RESULT ({ :min-id 0 })","title":"min"},{"location":"min/#min","text":"The min aggregate function allows you to find the lowest value across a set of rows. In this example, we take the minimum :id across the entire :Customer table. ;; QUERY [[ :from :Customer ] [ :agg [] [ :min-id [ min :id ]]]] ;; STATE { :Customer # {{ :id 0 } , { :id 1 } , { :id 2 }}} ;; RESULT ({ :min-id 0 })","title":"min"},{"location":"not-any/","text":"not-any An aggregate function that tests if for all rows in the group (pred row) returns false-or-nil, accepts a expr as an arg. e.g ;; in this example, we use any to test if no customers have an order total over 35 [[ :from :Order ] [ :agg [ :customer-id ] [ :no-high-valued-order [ rel/not-any [ <= 35.0 M :total ]]]]] ;; TABLE STATE { :Order [{ :customer-id 42 , :total 10.0 M } { :customer-id 42 , :total 12.0 M } { :customer-id 43 , :total 50.0 M }]} ;; RESULT [{ :customer-id 42 , :no-high-valued-order true } { :customer-id 43 , :no-high-valued-order false }]","title":"not-any"},{"location":"not-any/#not-any","text":"An aggregate function that tests if for all rows in the group (pred row) returns false-or-nil, accepts a expr as an arg. e.g ;; in this example, we use any to test if no customers have an order total over 35 [[ :from :Order ] [ :agg [ :customer-id ] [ :no-high-valued-order [ rel/not-any [ <= 35.0 M :total ]]]]] ;; TABLE STATE { :Order [{ :customer-id 42 , :total 10.0 M } { :customer-id 42 , :total 12.0 M } { :customer-id 43 , :total 50.0 M }]} ;; RESULT [{ :customer-id 42 , :no-high-valued-order true } { :customer-id 43 , :no-high-valued-order false }]","title":"not-any"},{"location":"qualify/","text":":qualify Qualify is a convenience form that lets you namespace all columns returned by a query. ;; QUERY [[ :from :Customer ] [ :qualify \"customer\" ]] ;; STATE { :Customer # {{ :id 42 , :name \"bob\" }}} ;; RESULTS ({ :customer/id 42 , :customer/name \"bob\" }) See also :rename","title":":qualify"},{"location":"qualify/#qualify","text":"Qualify is a convenience form that lets you namespace all columns returned by a query. ;; QUERY [[ :from :Customer ] [ :qualify \"customer\" ]] ;; STATE { :Customer # {{ :id 42 , :name \"bob\" }}} ;; RESULTS ({ :customer/id 42 , :customer/name \"bob\" }) See also :rename","title":":qualify"},{"location":"query/","text":"Query Programming relic is mostly about defining queries. A query is always a vector queries are made up of operations, themselves vectors of the form [operator & args] . ;; example query from the tpc-h benchmark suite [[ :from :lineitem ] [ :where [ <= :l_shipdate # inst \"1998-09-02\" ]] [ :agg [ :l_returnflag :l_linestatus ] [ :sum_qty [ rel/sum :l_quantity ]] [ :sum_base_price [ rel/sum :l_extendedprice ]] [ :sum_disc_price [ rel/sum [ * :l_extendedprice [ - 1 :l_discount ]]]] [ :sum_charge [ rel/sum [ * :l_extendedprice [ - 1 :l_discount ] [ + 1 :l_tax ]]]] [ :avg_qty [ rel/avg :l_quantity ]] [ :avg_price [ rel/avg :l_extendedprice ]] [ :avg_disc [ rel/avg :l_discount ]] [ :count_order count ]]] queries compose by adding to the vector, this is in contrast to other approaches where query optimisers take care of the overall ordering. In relic, data always flows top-to-bottom. The super-power is that relic allows you to materialize the query. This will convert the query into a DAG to support incremental re-computation as data in tables changes. With few exceptions (direct index lookup) you can materialize any query with rel/mat . Rationale of form In the tar pit paper, the language used to express its 'relvars' was a traditional expression tree (e.g union(a, b) ). I wanted a data-first clojure dsl that met two goals, like any good data dsl I wanted to compose using regular clojure functions, and I wanted them to be easy to write and read as literals without ide support. The vector form I think is close to SQL, with a nice top-to-bottom reading flow. Each operation is self-contained in its own delimited form, and so you can create new queries with conj , split them with split-at and so on. Operators :from a.k.a start here :where to select only certain rows :join sql style relation inner join :left-join sql style relational left join :extend compute new columns :select project a subset of columns, computations :without drop columns :expand flatten nested sequences :agg apply aggregates over rows in groups :sort sort rows :sort-limit sort with a limit :const provide a constant relation :difference set diff :intersection set intersection :union set union :rename rename columns :qualify qualify (namespace) columns Constraints :check ensure certain predicates hold :req ensure cols exist :fk ensure a referenced row exists in some other query/table :unique unsure only one row exists for some set of expressions :constrain combine multiple constraints on a query/table Indexes and direct index access :hash standard one-to-many hash index :btree standard one-to-many sorted index :lookup explicit index lookup","title":"Overview"},{"location":"query/#query","text":"Programming relic is mostly about defining queries. A query is always a vector queries are made up of operations, themselves vectors of the form [operator & args] . ;; example query from the tpc-h benchmark suite [[ :from :lineitem ] [ :where [ <= :l_shipdate # inst \"1998-09-02\" ]] [ :agg [ :l_returnflag :l_linestatus ] [ :sum_qty [ rel/sum :l_quantity ]] [ :sum_base_price [ rel/sum :l_extendedprice ]] [ :sum_disc_price [ rel/sum [ * :l_extendedprice [ - 1 :l_discount ]]]] [ :sum_charge [ rel/sum [ * :l_extendedprice [ - 1 :l_discount ] [ + 1 :l_tax ]]]] [ :avg_qty [ rel/avg :l_quantity ]] [ :avg_price [ rel/avg :l_extendedprice ]] [ :avg_disc [ rel/avg :l_discount ]] [ :count_order count ]]] queries compose by adding to the vector, this is in contrast to other approaches where query optimisers take care of the overall ordering. In relic, data always flows top-to-bottom. The super-power is that relic allows you to materialize the query. This will convert the query into a DAG to support incremental re-computation as data in tables changes. With few exceptions (direct index lookup) you can materialize any query with rel/mat .","title":"Query"},{"location":"query/#rationale-of-form","text":"In the tar pit paper, the language used to express its 'relvars' was a traditional expression tree (e.g union(a, b) ). I wanted a data-first clojure dsl that met two goals, like any good data dsl I wanted to compose using regular clojure functions, and I wanted them to be easy to write and read as literals without ide support. The vector form I think is close to SQL, with a nice top-to-bottom reading flow. Each operation is self-contained in its own delimited form, and so you can create new queries with conj , split them with split-at and so on.","title":"Rationale of form"},{"location":"query/#operators","text":":from a.k.a start here :where to select only certain rows :join sql style relation inner join :left-join sql style relational left join :extend compute new columns :select project a subset of columns, computations :without drop columns :expand flatten nested sequences :agg apply aggregates over rows in groups :sort sort rows :sort-limit sort with a limit :const provide a constant relation :difference set diff :intersection set intersection :union set union :rename rename columns :qualify qualify (namespace) columns","title":"Operators"},{"location":"query/#constraints","text":":check ensure certain predicates hold :req ensure cols exist :fk ensure a referenced row exists in some other query/table :unique unsure only one row exists for some set of expressions :constrain combine multiple constraints on a query/table","title":"Constraints"},{"location":"query/#indexes-and-direct-index-access","text":":hash standard one-to-many hash index :btree standard one-to-many sorted index :lookup explicit index lookup","title":"Indexes and direct index access"},{"location":"rename/","text":":rename Renames columns, take a map of {old-col new-col, ...} as an arg.","title":":rename"},{"location":"rename/#rename","text":"Renames columns, take a map of {old-col new-col, ...} as an arg.","title":":rename"},{"location":"replace-all/","text":":replace-all The :replace-all transact form lets you completely replace all rows in a table with a new set. It is the same as issuing [:delete table] [insert table row1, row2 ...] but can be more efficient. ( rel/transact db [[ :replace-all :Customer customer1 customer2 ]])","title":":replace-all"},{"location":"replace-all/#replace-all","text":"The :replace-all transact form lets you completely replace all rows in a table with a new set. It is the same as issuing [:delete table] [insert table row1, row2 ...] but can be more efficient. ( rel/transact db [[ :replace-all :Customer customer1 customer2 ]])","title":":replace-all"},{"location":"req/","text":":req The :req constraint ensures columns exist. It is short hand for a :check constraint. e.g [[ :from :Customer ] [ :req :customer/id :customer/firstname ]]","title":":req"},{"location":"req/#req","text":"The :req constraint ensures columns exist. It is short hand for a :check constraint. e.g [[ :from :Customer ] [ :req :customer/id :customer/firstname ]]","title":":req"},{"location":"security/","text":"Security Relic goes out of its way to be resistant to injection attacks with its design. As relic's support of clojure functions allows pretty arbitrary evaluation as part of a query, e.g [sh/sh \"rm\" \"-rf\" \"/\"] we need to mindful of security when processing untrusted user input. Protection offered by relic by default relic is careful about what is allowed in the prefix function position of relic expressions (a potential vector for injection) Relic allows: function objects (not symbols!), whitelisted sentinel values (that could not normally be constructed with edn/read ) safe keywords sentinels like :_ that cannot be used for exfiltration / eval, column keywords Out of these column keywords are the one to be worried about, although they do not provide opportunities for RCE, you should be wary of expressions like this [:extend [:my-col untrusted]] as they could be used to exfiltrate any data on the row. I suspect in practice this is very unlikely, but see escaping if you have this problem. I would advise in general to not allow user input to create arbitrary keywords as regardless of vectors against relic, it could be used to pollute the keyword cache and cause a DOS by increasing memory pressure / weak reference collection time. Escaping If you want to be absolutely sure, the :_ form can be used in expressions to ensure that the form is never interpreted and is treated as a normal value, even if a vector with a function in prefix position. e.g [:_ [sh/sh \"echo\" \"foo\"]] would just bind the value of [sh/sh \"echo\" \"foo\"] without evaluating sh/sh .","title":"Security"},{"location":"security/#security","text":"Relic goes out of its way to be resistant to injection attacks with its design. As relic's support of clojure functions allows pretty arbitrary evaluation as part of a query, e.g [sh/sh \"rm\" \"-rf\" \"/\"] we need to mindful of security when processing untrusted user input.","title":"Security"},{"location":"security/#protection-offered-by-relic-by-default","text":"relic is careful about what is allowed in the prefix function position of relic expressions (a potential vector for injection) Relic allows: function objects (not symbols!), whitelisted sentinel values (that could not normally be constructed with edn/read ) safe keywords sentinels like :_ that cannot be used for exfiltration / eval, column keywords Out of these column keywords are the one to be worried about, although they do not provide opportunities for RCE, you should be wary of expressions like this [:extend [:my-col untrusted]] as they could be used to exfiltrate any data on the row. I suspect in practice this is very unlikely, but see escaping if you have this problem. I would advise in general to not allow user input to create arbitrary keywords as regardless of vectors against relic, it could be used to pollute the keyword cache and cause a DOS by increasing memory pressure / weak reference collection time.","title":"Protection offered by relic by default"},{"location":"security/#escaping","text":"If you want to be absolutely sure, the :_ form can be used in expressions to ensure that the form is never interpreted and is treated as a normal value, even if a vector with a function in prefix position. e.g [:_ [sh/sh \"echo\" \"foo\"]] would just bind the value of [sh/sh \"echo\" \"foo\"] without evaluating sh/sh .","title":"Escaping"},{"location":"select/","text":":select The projection operator, takes columns & extension style bindings and returns only them. Form select = [ :select & col-or-extension ] col-or-binding = col | [ binding expr ] Examples [[ :from :Customer ] [ :select :firstname :lastname [ :fullname [ str :firstname \" \" :lastname ]]]]","title":":select"},{"location":"select/#select","text":"The projection operator, takes columns & extension style bindings and returns only them.","title":":select"},{"location":"select/#form","text":"select = [ :select & col-or-extension ] col-or-binding = col | [ binding expr ]","title":"Form"},{"location":"select/#examples","text":"[[ :from :Customer ] [ :select :firstname :lastname [ :fullname [ str :firstname \" \" :lastname ]]]]","title":"Examples"},{"location":"set-concat/","text":"set-concat The set-concat aggregation function can be used to bind a set of values across a group of rows. Takes an expression as an argument. ;; QUERY [[ :from :OrderItem ] [ :agg [ :order-id ] [ :items [ rel/set-concat :% ]]] ;; STATE { :OrderItem # {{ :order-id 0 , :product \"bread\" , :qty 2 } , { :order-id 0 , :product \"eggs\" , :qty 1 }}} ;; RESULTS ({ :order-id 0 , :items # {{ :order-id 0 , :product \"bread\" , :qty 2 } , { :order-id 1 , :product \"eggs\" , :qty 1 }}})","title":"set-concat"},{"location":"set-concat/#set-concat","text":"The set-concat aggregation function can be used to bind a set of values across a group of rows. Takes an expression as an argument. ;; QUERY [[ :from :OrderItem ] [ :agg [ :order-id ] [ :items [ rel/set-concat :% ]]] ;; STATE { :OrderItem # {{ :order-id 0 , :product \"bread\" , :qty 2 } , { :order-id 0 , :product \"eggs\" , :qty 1 }}} ;; RESULTS ({ :order-id 0 , :items # {{ :order-id 0 , :product \"bread\" , :qty 2 } , { :order-id 1 , :product \"eggs\" , :qty 1 }}})","title":"set-concat"},{"location":"sort-limit/","text":":sort-limit Like :sort but takes a limit param, for asking a query like the last 1000 events by timestamp. [[ :from :Event ] [ :sort-limit 1000 [ :ts :desc ] [ :event-type :asc ]]]","title":":sort-limit"},{"location":"sort-limit/#sort-limit","text":"Like :sort but takes a limit param, for asking a query like the last 1000 events by timestamp. [[ :from :Event ] [ :sort-limit 1000 [ :ts :desc ] [ :event-type :asc ]]]","title":":sort-limit"},{"location":"sort/","text":":sort The :sort operator allow you to sort rows by some sequence of expressions. :sort should be used in the terminal position of a query (e.g the last operation), otherwise the sort is not guaranteed. [[ :from :Customer ] [ :sort [ :age :desc ] [ :firstname :asc ]]] :sort takes vectors of [expr (:asc OR :desc)] for ascending and descending sorts. You can use any row expression in each sort expression as long all values are Comparable . Uses a btree index internally, so that it can be materialized .","title":":sort"},{"location":"sort/#sort","text":"The :sort operator allow you to sort rows by some sequence of expressions. :sort should be used in the terminal position of a query (e.g the last operation), otherwise the sort is not guaranteed. [[ :from :Customer ] [ :sort [ :age :desc ] [ :firstname :asc ]]] :sort takes vectors of [expr (:asc OR :desc)] for ascending and descending sorts. You can use any row expression in each sort expression as long all values are Comparable . Uses a btree index internally, so that it can be materialized .","title":":sort"},{"location":"sub-queries/","text":"Sub queries You can issue sub queries in relic by using the special forms rel/sel (select all) and rel/sel1 (select first) in relic expressions . Both take a table (or query) and a join clause as arguments. In the below example we use sub queries to select all OrderItems for a given Order. ;; QUERY [[ :from :Order ] [ :select :order-id [ :items [ rel/sel :OrderItem { :order-id :order-id }]]]] ;; STATE { :Order # {{ :order-id 0 }} :OrderItem # {{ :order-id 0 , :product \"eggs\" } , { :order-id 0 , :product \"bread\" } { :order-id 1 , :product \"cheese\" }}} ;; RESULTS [{ :order-id 0 , :items # {{ :order-id 0 , :product \"eggs\" } , { :order-id 0 , :product \"bread\" }}}] You can use sub queries in queries anywhere expressions are expected, for example - here we will use rel/sel1 for a sql-style exists check. ( def CustomersWithOrders [[ :from :Customer ] [ :where [ rel/sel1 :Order { :customer-id :customer-id }]]]) Sub queries can nest and multiple sub queries can be issued per operation, but the columns necessary to satisfy the joins must exist at the point the sub query is defined. Under the hood Sub queries are converted into implicit join dependencies, you do not actually issue a query for every single evaluation of an expression. They use indexes like joins do.","title":"Sub queries"},{"location":"sub-queries/#sub-queries","text":"You can issue sub queries in relic by using the special forms rel/sel (select all) and rel/sel1 (select first) in relic expressions . Both take a table (or query) and a join clause as arguments. In the below example we use sub queries to select all OrderItems for a given Order. ;; QUERY [[ :from :Order ] [ :select :order-id [ :items [ rel/sel :OrderItem { :order-id :order-id }]]]] ;; STATE { :Order # {{ :order-id 0 }} :OrderItem # {{ :order-id 0 , :product \"eggs\" } , { :order-id 0 , :product \"bread\" } { :order-id 1 , :product \"cheese\" }}} ;; RESULTS [{ :order-id 0 , :items # {{ :order-id 0 , :product \"eggs\" } , { :order-id 0 , :product \"bread\" }}}] You can use sub queries in queries anywhere expressions are expected, for example - here we will use rel/sel1 for a sql-style exists check. ( def CustomersWithOrders [[ :from :Customer ] [ :where [ rel/sel1 :Order { :customer-id :customer-id }]]]) Sub queries can nest and multiple sub queries can be issued per operation, but the columns necessary to satisfy the joins must exist at the point the sub query is defined.","title":"Sub queries"},{"location":"sub-queries/#under-the-hood","text":"Sub queries are converted into implicit join dependencies, you do not actually issue a query for every single evaluation of an expression. They use indexes like joins do.","title":"Under the hood"},{"location":"sum/","text":"sum The :sum aggregate function, sums over numeric columns in a group. Takes an expression as an argument. For example, lets total across all the orders. ;; QUERY [[ :from :Order ] [ :agg [] [ :total [ rel/sum :total ]]] ;; STATE { :Order # {{ :total 10.0 M } , { :total 15.30 M }}} ;; RESULTS ({ :total 25.30 M })","title":"sum"},{"location":"sum/#sum","text":"The :sum aggregate function, sums over numeric columns in a group. Takes an expression as an argument. For example, lets total across all the orders. ;; QUERY [[ :from :Order ] [ :agg [] [ :total [ rel/sum :total ]]] ;; STATE { :Order # {{ :total 10.0 M } , { :total 15.30 M }}} ;; RESULTS ({ :total 25.30 M })","title":"sum"},{"location":"terse-insert/","text":"Terser insert It can be convenient for example when constructing an initial database to throw data into the database using some initial state map. The terse input form allows you to insert into multiple tables with one transaction form. It is (potentially) faster too. ( rel/transact db { :Customer [{ :id 0 , :name \"Fred\" }] , :Order [{ :customer 0 , :total 10.0 M }]}) ;; is the same as ( rel/transact db [ :insert :Customer { :id 0 , :name \"Fred\" }] [ :insert :Order { :customer 0 , :total 10.0 M }]) See also :insert","title":"Terse Inserts"},{"location":"terse-insert/#terser-insert","text":"It can be convenient for example when constructing an initial database to throw data into the database using some initial state map. The terse input form allows you to insert into multiple tables with one transaction form. It is (potentially) faster too. ( rel/transact db { :Customer [{ :id 0 , :name \"Fred\" }] , :Order [{ :customer 0 , :total 10.0 M }]}) ;; is the same as ( rel/transact db [ :insert :Customer { :id 0 , :name \"Fred\" }] [ :insert :Order { :customer 0 , :total 10.0 M }]) See also :insert","title":"Terser insert"},{"location":"top-by/","text":"top-by An aggregate function that returns the highest n rows by some expr . In the below example, we bind the top 5 highest scoring players. ;; QUERY [[ :from :Player ] [ :agg [] [ :highest-scoring [ rel/top-by 5 :score ]]]] ;; STATE { :Player [{ :score 1 :name \"alice\" } { :score 200 :name \"bob\" } { :score 4323 :name \"fred\" } { :score 5555 :name \"hannah\" } { :score 4242 :name \"george\" } { :score -123 :name \"isabel\" } { :score 330 :name \"dave\" }]} ;; RESULT ({ :highest-scoring [{ :score 5555 , :name \"hannah\" } { :score 4323 , :name \"fred\" } { :score 4242 , :name \"george\" } { :score 330 , :name \"dave\" } { :score 200 , :name \"bob\" }]})","title":"top-by"},{"location":"top-by/#top-by","text":"An aggregate function that returns the highest n rows by some expr . In the below example, we bind the top 5 highest scoring players. ;; QUERY [[ :from :Player ] [ :agg [] [ :highest-scoring [ rel/top-by 5 :score ]]]] ;; STATE { :Player [{ :score 1 :name \"alice\" } { :score 200 :name \"bob\" } { :score 4323 :name \"fred\" } { :score 5555 :name \"hannah\" } { :score 4242 :name \"george\" } { :score -123 :name \"isabel\" } { :score 330 :name \"dave\" }]} ;; RESULT ({ :highest-scoring [{ :score 5555 , :name \"hannah\" } { :score 4323 , :name \"fred\" } { :score 4242 , :name \"george\" } { :score 330 , :name \"dave\" } { :score 200 , :name \"bob\" }]})","title":"top-by"},{"location":"top/","text":"top An aggregate functions that returns the highest n values for some expr across the group. In the below example we use top to find the highest 5 scores for a table of Player data. ;; QUERY [[ :from :Player ] [ :agg [] [ :highest-scores [ rel/top 5 :score ]]]] ;; STATE { :Player [{ :score 1 } { :score 200 } { :score 4323 } { :score 5555 } { :score 4242 } { :score -123 } { :score 330 }]} ;; EXPECTED [{ :highest-scores [ 5555 , 4323 , 4242 , 330 , 200 ]}]","title":"top"},{"location":"top/#top","text":"An aggregate functions that returns the highest n values for some expr across the group. In the below example we use top to find the highest 5 scores for a table of Player data. ;; QUERY [[ :from :Player ] [ :agg [] [ :highest-scores [ rel/top 5 :score ]]]] ;; STATE { :Player [{ :score 1 } { :score 200 } { :score 4323 } { :score 5555 } { :score 4242 } { :score -123 } { :score 330 }]} ;; EXPECTED [{ :highest-scores [ 5555 , 4323 , 4242 , 330 , 200 ]}]","title":"top"},{"location":"transact/","text":"Transactions Unless you are programming :const forms, you will need to manipulate tables and state in order to say anything useful. In relic, you manipulate your database with transact . transact is a function that accepts a database and a set of 'transaction ops', returning a new database with the ops applied. A key idea with relic is that you can only manipulate tables, and you try to keep data in tables to a minimum, rederiving everything else with queries. materialization enables high performance in the face of this. Ops You basic operations mirror the SQL ones, see the linked docs for more info. :insert :update :delete :delete-exact :insert-ignore :insert-or-replace :insert-or-merge :insert-or-update :replace-all terse insert Additional support A seq of ops is a valid op, this can sometimes save some boilerplate. A function from db -> op is a valid op, you can use this for gnarly dependent writes where pure data doesn't cut it. See also change tracking , constraints .","title":"transact"},{"location":"transact/#transactions","text":"Unless you are programming :const forms, you will need to manipulate tables and state in order to say anything useful. In relic, you manipulate your database with transact . transact is a function that accepts a database and a set of 'transaction ops', returning a new database with the ops applied. A key idea with relic is that you can only manipulate tables, and you try to keep data in tables to a minimum, rederiving everything else with queries. materialization enables high performance in the face of this.","title":"Transactions"},{"location":"transact/#ops","text":"You basic operations mirror the SQL ones, see the linked docs for more info. :insert :update :delete :delete-exact :insert-ignore :insert-or-replace :insert-or-merge :insert-or-update :replace-all terse insert","title":"Ops"},{"location":"transact/#additional-support","text":"A seq of ops is a valid op, this can sometimes save some boilerplate. A function from db -> op is a valid op, you can use this for gnarly dependent writes where pure data doesn't cut it. See also change tracking , constraints .","title":"Additional support"},{"location":"union/","text":":union Set union, returns rows in the left relations and each right relation. Accepts multiple tables/queries as parameters. Same kind of thing as clojure.set/union . Examples ( def Mary [[ :from :Customer ] [ :where [ = :firstname \"Mary\" ]]]) ( def John [[ :from :Customer ] [ :where [ = :firstname \"John\" ]]]) ( def JohnAndMary [[ :from John ] [ :union Mary ]]) ;; union doesn't need a left side ;; the below would also work. [[ :union John Mary ]]","title":":union"},{"location":"union/#union","text":"Set union, returns rows in the left relations and each right relation. Accepts multiple tables/queries as parameters. Same kind of thing as clojure.set/union .","title":":union"},{"location":"union/#examples","text":"( def Mary [[ :from :Customer ] [ :where [ = :firstname \"Mary\" ]]]) ( def John [[ :from :Customer ] [ :where [ = :firstname \"John\" ]]]) ( def JohnAndMary [[ :from John ] [ :union Mary ]]) ;; union doesn't need a left side ;; the below would also work. [[ :union John Mary ]]","title":"Examples"},{"location":"unique/","text":":unique The :unique operation creates a unique index & constraint. Normally you would use :unique indexes only as constraints, but they can be used as a performance hint. Here is an example of indexing customers by name. ;; QUERY ;; you index expressions, here I am going to use a single expression, ;; but I could use multiple and get a nested map, e.g [:unique :a, :b, :c] [[ :from :Customer ] [ :unique :name ]] ;; STATE { :Customer [{ :name \"bob\" , :age 42 } { :name \"alice\" , :age 23 }]} ;; INDEX ;; a clojure map ;; get with rel/index { \"bob\" { :name \"bob\" , :age 42 } \"alice\" { :name \"alice\" , :age 23 }}","title":":unique"},{"location":"unique/#unique","text":"The :unique operation creates a unique index & constraint. Normally you would use :unique indexes only as constraints, but they can be used as a performance hint. Here is an example of indexing customers by name. ;; QUERY ;; you index expressions, here I am going to use a single expression, ;; but I could use multiple and get a nested map, e.g [:unique :a, :b, :c] [[ :from :Customer ] [ :unique :name ]] ;; STATE { :Customer [{ :name \"bob\" , :age 42 } { :name \"alice\" , :age 23 }]} ;; INDEX ;; a clojure map ;; get with rel/index { \"bob\" { :name \"bob\" , :age 42 } \"alice\" { :name \"alice\" , :age 23 }}","title":":unique"},{"location":"update/","text":":update The :update transact operation allows you to modify existing rows by applying a function to them. In lieu of a function, a SQL style set-map can be used instead for column updates/overwrites. e.g ( def db ( rel/transact {} { :Counter [{ :n 0 }]})) ;; functions can be used ( rel/transact db [ :update :Counter # ( update % :n inc )]) ;; => { :Counter # {{ :n 1 }}} ;; a set map can be terser, it takes functions/relic-expressions in value position. ( rel/transact db [ :update :Counter { :n [ inc :n ]}]) ;; => { :Counter # {{ :n 1 }}} ;; as set maps take relic expressions, you can overwrite columns. ( rel/transact db [ :update :Counter { :n 42 }]) ;; => { :Counter # {{ :n 42 }}} ;; additional expresssions can be passed as args to filter updated rows ( rel/transact db [ :update :Counter { :n [ inc :n ]} [ even? :n ]]) ;; => {:Counter #{{:n 1}}} ( rel/transact db [ :update :Counter { :n [ inc :n ]} [ odd? :n ]]) ;; => {:Counter #{{:n 0}}}","title":":update"},{"location":"update/#update","text":"The :update transact operation allows you to modify existing rows by applying a function to them. In lieu of a function, a SQL style set-map can be used instead for column updates/overwrites. e.g ( def db ( rel/transact {} { :Counter [{ :n 0 }]})) ;; functions can be used ( rel/transact db [ :update :Counter # ( update % :n inc )]) ;; => { :Counter # {{ :n 1 }}} ;; a set map can be terser, it takes functions/relic-expressions in value position. ( rel/transact db [ :update :Counter { :n [ inc :n ]}]) ;; => { :Counter # {{ :n 1 }}} ;; as set maps take relic expressions, you can overwrite columns. ( rel/transact db [ :update :Counter { :n 42 }]) ;; => { :Counter # {{ :n 42 }}} ;; additional expresssions can be passed as args to filter updated rows ( rel/transact db [ :update :Counter { :n [ inc :n ]} [ even? :n ]]) ;; => {:Counter #{{:n 1}}} ( rel/transact db [ :update :Counter { :n [ inc :n ]} [ odd? :n ]]) ;; => {:Counter #{{:n 0}}}","title":":update"},{"location":"where/","text":":where Selects a subset of rows by applying predicate conditions to them before flowing onwards. Just like SQL WHERE . [[ :from :Customer ] [ :where [ < :age 42 ] [ = :name \"bob\" ]]] See expression reference for information on expressions.","title":":where"},{"location":"where/#where","text":"Selects a subset of rows by applying predicate conditions to them before flowing onwards. Just like SQL WHERE . [[ :from :Customer ] [ :where [ < :age 42 ] [ = :name \"bob\" ]]] See expression reference for information on expressions.","title":":where"},{"location":"without/","text":":without Removes columns, e.g like dissoc . [[ :from :Customer ] [ :without :age :firstname :lastname ]]","title":":without"},{"location":"without/#without","text":"Removes columns, e.g like dissoc . [[ :from :Customer ] [ :without :age :firstname :lastname ]]","title":":without"}]}